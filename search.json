[
  {
    "objectID": "03b_utils.misc.html",
    "href": "03b_utils.misc.html",
    "title": "ğŸ§‚ Misc utils",
    "section": "",
    "text": "test_array_repr(\"DeviceArray[2] Î¼=-0.466 Ïƒ=1.515 [-1.981, 1.048]\",\n                \"Array[2] Î¼=-0.466 gpu:0 Ïƒ=1.515 [-1.981, 1.048]\")\n\n\nbf16 = jnp.ones((10,10,3), dtype=jnp.bfloat16)\nbf16\n\nArray[10, 10, 3] bf16 n=300 xâˆˆ[1.000, 1.000] Î¼=0.852 Ïƒ=0.149 cpu:0\n\n\n\nbf16.plt\n\n\n\n\n\n\n\n\n\nbf16.rgb\n\n\n\n\n\n\n\n\n\nbf16.chans\n\n\n\n\n\n\n\n\n\n# key = jax.random.PRNGKey(0)\n\n# cpu = jax.devices(\"cpu\")[0]\n\n# x1 = jax.device_put(jax.random.normal(key, (1024, 1024)), cpu)\n# x2 = jax.device_put(jax.random.normal(key, (1024, 1024)), cpu)\n\n# %timeit np.dot(np.array(x1), np.array(x2))"
  },
  {
    "objectID": "patch.html",
    "href": "patch.html",
    "title": "ğŸ™ˆ Monkey-patching",
    "section": "",
    "text": "source\n\nmonkey_patch\n\n monkey_patch ()\n\n\nmonkey_patch()\n\n\nimage = jnp.load(\"mysteryman.npy\").transpose(1,2,0)\n\n\nspicy = image[0,:12,0].copy()\n\nspicy = (spicy  .at[0].mul(10000)\n                .at[1].divide(10000)\n                .at[2].set(float('inf'))\n                .at[3].set(float('-inf'))\n                .at[4].set(float('nan'))\n                .reshape((2,6)))\n\nspicy\n\n\nArray[2, 6] n=12 xâˆˆ[-3.541e+03, -3.369e-05] Î¼=-393.776 Ïƒ=1.113e+03 +Inf! -Inf! NaN! cpu:0\n\n\n\n\nspicy.v # Verbose\n\n\nArray[2, 6] n=12 xâˆˆ[-3.541e+03, -3.369e-05] Î¼=-393.776 Ïƒ=1.113e+03 +Inf! -Inf! NaN! cpu:0\nArray([[-3.5405432e+03, -3.3692955e-05,            inf,           -inf,\n                   nan, -4.0542859e-01],\n       [-4.2255333e-01, -4.9105233e-01, -5.0817710e-01, -5.5955136e-01,\n        -5.4242659e-01, -5.0817710e-01]], dtype=float32)\n\n\n\n\nspicy.p # Plain\n\nArray([[-3.5405432e+03, -3.3692955e-05,            inf,           -inf,\n                   nan, -4.0542859e-01],\n       [-4.2255333e-01, -4.9105233e-01, -5.0817710e-01, -5.5955136e-01,\n        -5.4242659e-01, -5.0817710e-01]], dtype=float32)\n\n\n\nimage.deeper\n\nArray[196, 196, 3] n=115248 (0.4Mb) xâˆˆ[-2.118, 2.640] Î¼=-0.388 Ïƒ=1.073 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.912, 2.411] Î¼=-0.728 Ïƒ=0.519 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.861, 2.359] Î¼=-0.778 Ïƒ=0.450 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.758, 2.379] Î¼=-0.838 Ïƒ=0.437 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.656, 2.466] Î¼=-0.878 Ïƒ=0.415 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.717, 2.448] Î¼=-0.882 Ïƒ=0.399 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.717, 2.431] Î¼=-0.905 Ïƒ=0.408 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.563, 2.448] Î¼=-0.859 Ïƒ=0.416 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.475, 2.431] Î¼=-0.791 Ïƒ=0.463 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.526, 2.429] Î¼=-0.759 Ïƒ=0.499 cpu:0\n  ...\n\n\n\ndt = image[:3,:5,:3]\ndt.deeper(3)\n\nArray[3, 5, 3] n=45 xâˆˆ[-1.316, -0.197] Î¼=-0.593 Ïƒ=0.302 cpu:0\n  Array[5, 3] n=15 xâˆˆ[-0.985, -0.197] Î¼=-0.491 Ïƒ=0.267 cpu:0\n    Array[3] xâˆˆ[-0.672, -0.197] Î¼=-0.408 Ïƒ=0.197 cpu:0 [-0.354, -0.197, -0.672]\n    Array[3] xâˆˆ[-0.985, -0.197] Î¼=-0.507 Ïƒ=0.343 cpu:0 [-0.337, -0.197, -0.985]\n    Array[3] xâˆˆ[-0.881, -0.303] Î¼=-0.530 Ïƒ=0.252 cpu:0 [-0.405, -0.303, -0.881]\n    Array[3] xâˆˆ[-0.776, -0.303] Î¼=-0.506 Ïƒ=0.199 cpu:0 [-0.440, -0.303, -0.776]\n    Array[3] xâˆˆ[-0.916, -0.215] Î¼=-0.506 Ïƒ=0.298 cpu:0 [-0.388, -0.215, -0.916]\n  Array[5, 3] n=15 xâˆˆ[-1.212, -0.232] Î¼=-0.609 Ïƒ=0.302 cpu:0\n    Array[3] xâˆˆ[-0.724, -0.250] Î¼=-0.460 Ïƒ=0.197 cpu:0 [-0.405, -0.250, -0.724]\n    Array[3] xâˆˆ[-1.072, -0.232] Î¼=-0.576 Ïƒ=0.360 cpu:0 [-0.423, -0.232, -1.072]\n    Array[3] xâˆˆ[-0.968, -0.338] Î¼=-0.599 Ïƒ=0.268 cpu:0 [-0.491, -0.338, -0.968]\n    Array[3] xâˆˆ[-0.968, -0.408] Î¼=-0.651 Ïƒ=0.235 cpu:0 [-0.577, -0.408, -0.968]\n    Array[3] xâˆˆ[-1.212, -0.408] Î¼=-0.761 Ïƒ=0.336 cpu:0 [-0.662, -0.408, -1.212]\n  Array[5, 3] n=15 xâˆˆ[-1.316, -0.285] Î¼=-0.677 Ïƒ=0.306 cpu:0\n    Array[3] xâˆˆ[-0.828, -0.303] Î¼=-0.535 Ïƒ=0.219 cpu:0 [-0.474, -0.303, -0.828]\n    Array[3] xâˆˆ[-1.125, -0.285] Î¼=-0.628 Ïƒ=0.360 cpu:0 [-0.474, -0.285, -1.125]\n    Array[3] xâˆˆ[-1.020, -0.390] Î¼=-0.651 Ïƒ=0.268 cpu:0 [-0.542, -0.390, -1.020]\n    Array[3] xâˆˆ[-1.003, -0.478] Î¼=-0.708 Ïƒ=0.219 cpu:0 [-0.645, -0.478, -1.003]\n    Array[3] xâˆˆ[-1.316, -0.513] Î¼=-0.865 Ïƒ=0.336 cpu:0 [-0.765, -0.513, -1.316]\n\n\n\nimage.rgb\n\n\n\n\n\n\n\n\n\nin_stats = ( (0.485, 0.456, 0.406),     # mean\n             (0.229, 0.224, 0.225) )    # std\nimage.rgb(in_stats)\n\n\n\n\n\n\n\n\n\n(image*0.3+0.5) # Slightly outside of [0, 1] range\n\nArray[196, 196, 3] n=115248 (0.4Mb) xâˆˆ[-0.135, 1.292] Î¼=0.384 Ïƒ=0.322 cpu:0\n\n\n\n(image*0.3+0.5).chans # shows clipping (bright blue/red)\n\n\n\n\n\n\n\n\n\nimage.plt\n\n\n\n\n\n\n\n\n\nimage.plt(center=\"mean\")\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(6, 2))\nplt.close(fig)\nimage.plt(ax=ax)\nfig",
    "crumbs": [
      "Misc",
      "ğŸ™ˆ Monkey-patching"
    ]
  },
  {
    "objectID": "repr_str.html",
    "href": "repr_str.html",
    "title": "ğŸ§¾ View as a summary",
    "section": "",
    "text": "spicy = (randoms[:12].at[0].mul(10000)\n                    .at[1].divide(10000)\n                    .at[3].set(float('inf'))\n                    .at[4].set(float('-inf'))\n                    .at[5].set(float('nan'))\n                    .reshape((2,6)))\n\n\nsource\n\njax_to_str_common\n\n jax_to_str_common (x:jax.Array, color=True, ddof=0)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nArray\n\nInput\n\n\ncolor\nbool\nTrue\nANSI color highlighting\n\n\nddof\nint\n0\nFor â€œstdâ€ unbiasing\n\n\n\n\nsource\n\n\nlovely\n\n lovely (x:jax.Array, verbose=False, plain=False, depth=0, color=None)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nArray\n\nTensor of interest\n\n\nverbose\nbool\nFalse\nWhether to show the full tensor\n\n\nplain\nbool\nFalse\nJust print if exactly as before\n\n\ndepth\nint\n0\nShow stats in depth\n\n\ncolor\nNoneType\nNone\nForce color (True/False) or auto.\n\n\n\n\n\nExamples\n\nprint(lovely(randoms[0]))\nprint(lovely(randoms[:2]))\nprint(lovely(randoms[:6].reshape((2, 3)))) # More than 2 elements -&gt; show statistics\nprint(lovely(randoms[:11]))           # More than 10 -&gt; suppress data output\n\nArray cpu:0 1.623\nArray[2] Î¼=1.824 Ïƒ=0.201 cpu:0 [1.623, 2.025]\nArray[2, 3] n=6 xâˆˆ[-0.972, 2.025] Î¼=0.390 Ïƒ=1.080 cpu:0 [[1.623, 2.025, -0.434], [-0.079, 0.176, -0.972]]\nArray[11] xâˆˆ[-0.972, 2.180] Î¼=0.385 Ïƒ=1.081 cpu:0\n\n\n\ngrad = jnp.array(1., dtype=jnp.float16)\nprint(lovely(grad)); print(lovely(grad+1))\n\nArray f16 cpu:0 1.000\nArray f16 cpu:0 2.000\n\n\n\n# if torch.cuda.is_available():\n#     print(lovely(torch.tensor(1., device=torch.device(\"cuda:0\"))))\n#     test_eq(str(lovely(torch.tensor(1., device=torch.device(\"cuda:0\")))), \"tensor cuda:0 1.000\")\n\nDo we have any floating point nasties? Is the tensor all zeros?\n\n# Statistics and range are calculated on good values only, if there are at lest 3 of them.\nlovely(spicy)\n\n\nArray[2, 6] n=12 xâˆˆ[-1.955, 1.623e+04] Î¼=1.803e+03 Ïƒ=5.099e+03 +Inf! -Inf! NaN! cpu:0\n\n\n\n\nlovely(spicy, color=False)\n\nArray[2, 6] n=12 xâˆˆ[-1.955, 1.623e+04] Î¼=1.803e+03 Ïƒ=5.099e+03 +Inf! -Inf! NaN! cpu:0\n\n\n\nstr(lovely(jnp.array([float(\"nan\")]*11)))\n\n'Array[11] \\x1b[31mNaN!\\x1b[0m cpu:0'\n\n\n\nlovely(jnp.zeros(12))\n\n\nArray[12] all_zeros cpu:0\n\n\n\n\nlovely(jnp.array([], dtype=jnp.float16).reshape((0,0,0)))\n\n\nArray[0, 0, 0] f16 empty cpu:0\n\n\n\n\nlovely(jnp.array([1,2,3], dtype=jnp.int32))\n\nArray[3] i32 xâˆˆ[1, 3] Î¼=2.000 Ïƒ=0.816 cpu:0 [1, 2, 3]\n\n\n\njnp.set_printoptions(linewidth=120, precision=2)\nlovely(spicy, verbose=True)\n\n\nArray[2, 6] n=12 xâˆˆ[-1.955, 1.623e+04] Î¼=1.803e+03 Ïƒ=5.099e+03 +Inf! -Inf! NaN! cpu:0\nArray([[ 1.62e+04,  2.03e-04, -4.34e-01,       inf,      -inf,       nan],\n       [-4.95e-01,  4.94e-01,  6.64e-01, -9.50e-01,  2.18e+00, -1.96e+00]], dtype=float32)\n\n\n\n\nlovely(spicy, plain=True)\n\nArray([[ 1.6226422e+04,  2.0252647e-04, -4.3359444e-01,            inf,\n                  -inf,            nan],\n       [-4.9529874e-01,  4.9437860e-01,  6.6434932e-01, -9.5016348e-01,\n         2.1795304e+00, -1.9551506e+00]], dtype=float32)\n\n\n\nimage = jnp.load(\"mysteryman.npy\")\nimage = image.at[1,2,3].set(float('nan'))\n\nlovely(image, depth=2) # Limited by set_config(deeper_lines=N)\n\n\nArray[3, 196, 196] n=115248 (0.4Mb) xâˆˆ[-2.118, 2.640] Î¼=-0.388 Ïƒ=1.073 NaN! cpu:0\n  Array[196, 196] n=38416 xâˆˆ[-2.118, 2.249] Î¼=-0.324 Ïƒ=1.036 cpu:0\n    Array[196] xâˆˆ[-1.912, 2.249] Î¼=-0.673 Ïƒ=0.521 cpu:0\n    Array[196] xâˆˆ[-1.861, 2.163] Î¼=-0.738 Ïƒ=0.417 cpu:0\n    Array[196] xâˆˆ[-1.758, 2.198] Î¼=-0.806 Ïƒ=0.396 cpu:0\n    Array[196] xâˆˆ[-1.656, 2.249] Î¼=-0.849 Ïƒ=0.368 cpu:0\n    Array[196] xâˆˆ[-1.673, 2.198] Î¼=-0.857 Ïƒ=0.356 cpu:0\n    Array[196] xâˆˆ[-1.656, 2.146] Î¼=-0.848 Ïƒ=0.371 cpu:0\n    Array[196] xâˆˆ[-1.433, 2.215] Î¼=-0.784 Ïƒ=0.396 cpu:0\n    Array[196] xâˆˆ[-1.279, 2.249] Î¼=-0.695 Ïƒ=0.485 cpu:0\n    Array[196] xâˆˆ[-1.364, 2.249] Î¼=-0.637 Ïƒ=0.538 cpu:0\n    ...\n  Array[196, 196] n=38416 xâˆˆ[-1.966, 2.429] Î¼=-0.274 Ïƒ=0.973 NaN! cpu:0\n    Array[196] xâˆˆ[-1.861, 2.411] Î¼=-0.529 Ïƒ=0.555 cpu:0\n    Array[196] xâˆˆ[-1.826, 2.359] Î¼=-0.562 Ïƒ=0.472 cpu:0\n    Array[196] xâˆˆ[-1.756, 2.376] Î¼=-0.622 Ïƒ=0.458 NaN! cpu:0\n    Array[196] xâˆˆ[-1.633, 2.429] Î¼=-0.664 Ïƒ=0.429 cpu:0\n    Array[196] xâˆˆ[-1.651, 2.376] Î¼=-0.669 Ïƒ=0.398 cpu:0\n    Array[196] xâˆˆ[-1.633, 2.376] Î¼=-0.701 Ïƒ=0.390 cpu:0\n    Array[196] xâˆˆ[-1.563, 2.429] Î¼=-0.670 Ïƒ=0.379 cpu:0\n    Array[196] xâˆˆ[-1.475, 2.429] Î¼=-0.616 Ïƒ=0.385 cpu:0\n    Array[196] xâˆˆ[-1.511, 2.429] Î¼=-0.593 Ïƒ=0.398 cpu:0\n    ...\n  Array[196, 196] n=38416 xâˆˆ[-1.804, 2.640] Î¼=-0.567 Ïƒ=1.178 cpu:0\n    Array[196] xâˆˆ[-1.717, 2.396] Î¼=-0.982 Ïƒ=0.349 cpu:0\n    Array[196] xâˆˆ[-1.752, 2.326] Î¼=-1.034 Ïƒ=0.313 cpu:0\n    Array[196] xâˆˆ[-1.648, 2.379] Î¼=-1.086 Ïƒ=0.313 cpu:0\n    Array[196] xâˆˆ[-1.630, 2.466] Î¼=-1.121 Ïƒ=0.304 cpu:0\n    Array[196] xâˆˆ[-1.717, 2.448] Î¼=-1.120 Ïƒ=0.301 cpu:0\n    Array[196] xâˆˆ[-1.717, 2.431] Î¼=-1.166 Ïƒ=0.313 cpu:0\n    Array[196] xâˆˆ[-1.560, 2.448] Î¼=-1.124 Ïƒ=0.325 cpu:0\n    Array[196] xâˆˆ[-1.421, 2.431] Î¼=-1.064 Ïƒ=0.382 cpu:0\n    Array[196] xâˆˆ[-1.526, 2.396] Î¼=-1.047 Ïƒ=0.416 cpu:0\n    ...\n\n\n\n\n# We don't really supposed complex numbers yet\nc = jnp.array([-0.4011-0.4035j,  1.1300+0.0788j, -0.0277+0.9978j, -0.4636+0.6064j, -1.1505-0.9865j])\nlovely(c)\n\nArray([-0.4011-0.4035j,  1.13  +0.0788j, -0.0277+0.9978j, -0.4636+0.6064j,\n       -1.1505-0.9865j], dtype=complex64)\n\n\n\nassert jax.__version_info__[0] == 0\nfrom jax.sharding import NamedSharding, Mesh, PartitionSpec as P\nfrom jax.experimental import mesh_utils\n\nprint(\"=== Test 1: NamedSharding with 2D mesh (4,2) and P('y', 'x') ===\")\ndevices = mesh_utils.create_device_mesh((4, 2))\nmesh = Mesh(devices, axis_names=('y', 'x'))  # x has 4 devices, y has 2\nsharding = NamedSharding(mesh, P('y', 'x'))  # Shard array dim 0 across y, dim 1 across x\n\nx = jax.random.normal(jax.random.PRNGKey(0), (8192, 8192))\ny = jax.device_put(x, sharding)\n\njax.debug.visualize_array_sharding(y)\nprint(lovely(y))\n\nprint(\"\\n=== Test 2: NamedSharding with P('y', None) - replicate first dim ===\")\nsharding2 = NamedSharding(mesh, P('y', None))\ny2 = jax.device_put(x, sharding2)\njax.debug.visualize_array_sharding(y2)\nprint(lovely(y2))\n\nprint(\"\\n=== Test 3: NamedSharding with P(None, 'x') - replicate second dim ===\")\nsharding3 = NamedSharding(mesh, P(None, 'x'))\ny3 = jax.device_put(x, sharding3)\njax.debug.visualize_array_sharding(y3)\nprint(lovely(y3))\n\nprint(\"\\n=== Test 4: 1D mesh with 8 devices ===\")\ndevices_1d = mesh_utils.create_device_mesh((8,))\nmesh_1d = Mesh(devices_1d, axis_names=('x',))\nsharding_1d = NamedSharding(mesh_1d, P('x', None))\ny4 = jax.device_put(x, sharding_1d)\njax.debug.visualize_array_sharding(y4)\nprint(lovely(y4))\n\n=== Test 1: NamedSharding with 2D mesh (4,2) and P('y', 'x') ===\n\n\n                        \n   CPU 0       CPU 1    \n                        \n                        \n   CPU 2       CPU 3    \n                        \n                        \n   CPU 4       CPU 5    \n                        \n                        \n   CPU 6       CPU 7    \n                        \n\n\n\nArray[8192, 8192] n=67108864 (0.2Gb) xâˆˆ[-5.420, 5.220] Î¼=1.508e-05 Ïƒ=1.000 S[y,x] 4Ã—2 cpu:0-7\n\n=== Test 2: NamedSharding with P('y', None) - replicate first dim ===\n\n\n                         \n         CPU 0,1         \n                         \n                         \n         CPU 2,3         \n                         \n                         \n         CPU 4,5         \n                         \n                         \n         CPU 6,7         \n                         \n\n\n\nArray[8192, 8192] n=67108864 (0.2Gb) xâˆˆ[-5.420, 5.220] Î¼=1.508e-05 Ïƒ=1.000 S[y,Â·] 4Ã—2 cpu:0-7\n\n=== Test 3: NamedSharding with P(None, 'x') - replicate second dim ===\n\n\n                        \n                        \n                        \n                        \n                        \nCPU 0,2,4,6 CPU 1,3,5,7 \n                        \n                        \n                        \n                        \n                        \n\n\n\nArray[8192, 8192] n=67108864 (0.2Gb) xâˆˆ[-5.420, 5.220] Î¼=1.508e-05 Ïƒ=1.000 S[Â·,x] 4Ã—2 cpu:0-7\n\n=== Test 4: 1D mesh with 8 devices ===\n\n\n          CPU 0          \n                         \n          CPU 1          \n                         \n          CPU 2          \n                         \n          CPU 3          \n                         \n          CPU 4          \n                         \n          CPU 5          \n                         \n          CPU 6          \n                         \n          CPU 7          \n                         \n\n\n\nArray[8192, 8192] n=67108864 (0.2Gb) xâˆˆ[-5.420, 5.220] Î¼=1.508e-05 Ïƒ=1.000 S[x,Â·] cpu:0-7",
    "crumbs": [
      "Data representations",
      "ğŸ§¾ View as a summary"
    ]
  },
  {
    "objectID": "repr_plt.html",
    "href": "repr_plt.html",
    "title": "ğŸ“Š View as a histogram",
    "section": "",
    "text": "source\n\nplot\n\n plot (x:jax.Array, center:str='zero', max_s:int=10000, plt0:Any=True,\n       ax:Optional[matplotlib.axes._axes.Axes]=None)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nArray\n\nTensor to explore\n\n\ncenter\nstr\nzero\nCenter plot on zero, mean, or range\n\n\nmax_s\nint\n10000\nDraw up to this many samples. =0 to draw all\n\n\nplt0\nAny\nTrue\nTake zero values into account\n\n\nax\nOptional\nNone\nOptionally provide a matplotlib axes.\n\n\nReturns\nPlotProxy\n\n\n\n\n\n\nkey = jax.random.PRNGKey(0)\nt = jax.random.normal(key, (1000000,))+3\n\nplot(t)\n\n\n\n\n\n\n\n\n\nplot(t, center=\"range\")\n\n\n\n\n\n\n\n\n\nplot(t, center=\"mean\")\n\n\n\n\n\n\n\n\n\nplot(jnp.maximum(t-3, 0))\n\n\n\n\n\n\n\n\n\nplot(jnp.maximum(t-3, 0), plt0=False)\n\n\n\n\n\n\n\n\n\nfig, ax, = plt.subplots(figsize=(6, 2))\nfig.tight_layout()\nplot(t, ax=ax);",
    "crumbs": [
      "Data representations",
      "ğŸ“Š View as a histogram"
    ]
  },
  {
    "objectID": "repr_rgb.html",
    "href": "repr_rgb.html",
    "title": "ğŸ–Œï¸ View as RGB images",
    "section": "",
    "text": "monkey_patch()\n\n\nsource\n\nrgb\n\n rgb (x:jax.Array, denorm:Any=None, cl:Any=True, gutter_px:int=3,\n      frame_px:int=1, scale:int=1, view_width:int=966,\n      ax:Optional[matplotlib.axes._axes.Axes]=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nArray\n\nTensor to display. [[â€¦], C,H,W] or [[â€¦], H,W,C]\n\n\ndenorm\nAny\nNone\nReverse per-channel normalizatoin\n\n\ncl\nAny\nTrue\nChannel-last\n\n\ngutter_px\nint\n3\nIf more than one tensor -&gt; tile with this gutter width\n\n\nframe_px\nint\n1\nIf more than one tensor -&gt; tile with this frame width\n\n\nscale\nint\n1\nScale up. Canâ€™t scale down.\n\n\nview_width\nint\n966\ntarget width of the image\n\n\nax\nOptional\nNone\nUse this Axes\n\n\nReturns\nRGBProxy\n\n\n\n\n\n\nrgb(image)\n\n\n\n\n\n\n\n\n\nrgb(image, scale=2)\n\n\n\n\n\n\n\n\n\ntwo_images = jnp.stack([image]*2)\ntwo_images\n\nArray[2, 196, 196, 3] n=230496 (0.9Mb) xâˆˆ[-2.118, 2.640] Î¼=-0.388 Ïƒ=1.073 cpu:0\n\n\n\nin_stats = (    (0.485, 0.456, 0.406),  # Mean\n                (0.229, 0.224, 0.225) ) # std\nrgb(two_images, denorm=in_stats)\n\n\n\n\n\n\n\n\n\n# Make 8 images with progressively higher brightness and stack them 2x2x2.\n\neight_images = (jnp.stack([image]*8) + jnp.linspace(-2, 2, 8)[:,None,None,None])\neight_images = (eight_images\n                     *jnp.array(in_stats[1])\n                     +jnp.array(in_stats[0])\n                ).clip(0,1).reshape(2,2,2,196,196,3)\n\neight_images\n\nArray[2, 2, 2, 196, 196, 3] n=921984 (3.5Mb) xâˆˆ[0., 1.000] Î¼=0.382 Ïƒ=0.319 cpu:0\n\n\n\nrgb(eight_images)\n\n\n\n\n\n\n\n\n\n# You can do channel-last too:\nrgb(image.transpose(2, 0, 1), cl=False)",
    "crumbs": [
      "Data representations",
      "ğŸ–Œï¸ View as RGB images"
    ]
  },
  {
    "objectID": "utils.config.html",
    "href": "utils.config.html",
    "title": "ğŸ¤” Config",
    "section": "",
    "text": "Type\nDefault\nDetails\n\n\n\n\nprecision\nint\n3\nDigits after .\n\n\nthreshold_max\nint\n3\n.abs() larger than 1e3 -&gt; Sci mode\n\n\nthreshold_min\nint\n-4\n.abs() smaller that 1e-4 -&gt; Sci mode\n\n\nsci_mode\nNoneType\nNone\nSci mode (2.3e4). None=auto\n\n\nshow_mem_above\nint\n1024\nShow memory footprint above this size\n\n\nindent\nint\n2\nIndent for .deeper()\n\n\ncolor\nbool\nTrue\nANSI colors in text\n\n\ndeeper_width\nint\n9\nFor .deeper, width per level\n\n\nplt_seed\nint\n42\nSampling seed for plot\n\n\nfig_close\nbool\nTrue\nClose matplotlib Figure\n\n\nfig_show\nbool\nFalse\nCall plt.show() for .plt, .chans and .rgb\n\n\n\n\n\n\nsource",
    "crumbs": [
      "Misc",
      "ğŸ¤” Config"
    ]
  },
  {
    "objectID": "utils.config.html#examples",
    "href": "utils.config.html#examples",
    "title": "ğŸ¤” Config",
    "section": "Examples",
    "text": "Examples\n\nimport jax.numpy as jnp\nfrom lovely_jax import set_config, config, monkey_patch\n\n\nmonkey_patch()\n\n\nPrecision\n\nset_config(precision=5)\njnp.array([1., 2, jnp.nan])\n\n\nArray[3] Î¼=1.50000 Ïƒ=0.50000 NaN! cpu:0 [1.00000, 2.00000, nan]\n\n\n\n\njnp.array([1., 2, jnp.nan])\n\n\nArray[3] Î¼=1.50000 Ïƒ=0.50000 NaN! cpu:0 [1.00000, 2.00000, nan]\n\n\n\n\n\nScientific mode\n\nset_config(sci_mode=True) # Force always on\nstr(jnp.array([1., 2, jnp.nan]))\n\n'Array[3] Î¼=1.50000e+00 Ïƒ=5.00000e-01 \\x1b[31mNaN!\\x1b[0m cpu:0 [1.00000e+00, 2.00000e+00, nan]'\n\n\n\n\nColor on/off\n\nset_config(color=False) # Force always off\njnp.array([1., 2, jnp.nan])\n\nArray[3] Î¼=1.50000e+00 Ïƒ=5.00000e-01 NaN! cpu:0 [1.00000e+00, 2.00000e+00, nan]\n\n\n\ntest_array_repr(str(jnp.array([1., 2, jnp.nan])),\n        'Array[3] Î¼=1.50000e+00 Ïƒ=5.00000e-01 NaN! gpu:0 [1.00000e+00, 2.00000e+00, nan]')\n\n\n\nControl .deeper\n\nset_config(deeper_width=3)\nimage = jnp.load(\"mysteryman.npy\")\nimage = image.at[1,100,100].set(jnp.nan)\n\nimage.deeper(2)\n\nArray[3, 196, 196] n=115248 (0.4Mb) xâˆˆ[-2.11790e+00, 2.64000e+00] Î¼=-3.88310e-01 Ïƒ=1.07318e+00 NaN! cpu:0\n  Array[196, 196] n=38416 xâˆˆ[-2.11790e+00, 2.24891e+00] Î¼=-3.24352e-01 Ïƒ=1.03586e+00 cpu:0\n    Array[196] xâˆˆ[-1.91241e+00, 2.24891e+00] Î¼=-6.73483e-01 Ïƒ=5.20629e-01 cpu:0\n    Array[196] xâˆˆ[-1.86103e+00, 2.16328e+00] Î¼=-7.38488e-01 Ïƒ=4.17012e-01 cpu:0\n    Array[196] xâˆˆ[-1.75828e+00, 2.19753e+00] Î¼=-8.05501e-01 Ïƒ=3.95835e-01 cpu:0\n    ...\n  Array[196, 196] n=38416 xâˆˆ[-1.96569e+00, 2.42857e+00] Î¼=-2.73903e-01 Ïƒ=9.72652e-01 NaN! cpu:0\n    Array[196] xâˆˆ[-1.86064e+00, 2.41106e+00] Î¼=-5.28772e-01 Ïƒ=5.54540e-01 cpu:0\n    Array[196] xâˆˆ[-1.82563e+00, 2.35854e+00] Î¼=-5.61732e-01 Ïƒ=4.71564e-01 cpu:0\n    Array[196] xâˆˆ[-1.75560e+00, 2.37605e+00] Î¼=-6.21756e-01 Ïƒ=4.57265e-01 cpu:0\n    ...\n  Array[196, 196] n=38416 xâˆˆ[-1.80444e+00, 2.64000e+00] Î¼=-5.66674e-01 Ïƒ=1.17775e+00 cpu:0\n    Array[196] xâˆˆ[-1.71730e+00, 2.39599e+00] Î¼=-9.81537e-01 Ïƒ=3.49106e-01 cpu:0\n    Array[196] xâˆˆ[-1.75216e+00, 2.32627e+00] Î¼=-1.03418e+00 Ïƒ=3.13168e-01 cpu:0\n    Array[196] xâˆˆ[-1.64758e+00, 2.37856e+00] Î¼=-1.08647e+00 Ïƒ=3.13411e-01 cpu:0\n    ...\n\n\n\ntest_eq(len(str(image.deeper(2))), 1127)\n\n\n\nReser to defaults\n\nset_config(precision=None, sci_mode=None, color=None, deeper_width=None)\nstr(jnp.array([1., 2, jnp.nan]))\n\n'Array[3] Î¼=1.500 Ïƒ=0.500 \\x1b[31mNaN!\\x1b[0m cpu:0 [1.000, 2.000, nan]'\n\n\n\ntest_array_repr(str(jnp.array([1., 2, jnp.nan])),\n    'Array[3] Î¼=1.500 Ïƒ=0.500 \\x1b[31mNaN!\\x1b[0m gpu:0 [1.000, 2.000, nan]')\n\n\n\nContext manager\n\ndisplay(jnp.array([1., 2, jnp.nan]))\nwith config(sci_mode=True, color=False):\n    display(jnp.array([1., 2, jnp.nan]))\ndisplay(jnp.array([1., 2, jnp.nan]))\n\n\nArray[3] Î¼=1.500 Ïƒ=0.500 NaN! cpu:0 [1.000, 2.000, nan]\n\n\n\nArray[3] Î¼=1.500e+00 Ïƒ=5.000e-01 NaN! cpu:0 [1.000e+00, 2.000e+00, nan]\n\n\n\nArray[3] Î¼=1.500 Ïƒ=0.500 NaN! cpu:0 [1.000, 2.000, nan]\n\n\n\n\n\nMatplotlib and seed\n\n# torch.manual_seed(42)\n# a = torch.randn(1000)\n\nkey = jax.random.PRNGKey(0)\na = jax.random.normal(key, (1000,))\n\n\n_ = a.plt() # The figure was closed, nothing is displayed\n\n\nset_config(fig_close=False)\n_ = a.plt() # figure was not closed. All figures that are not closed are displayed after the cell runs.\n\n\n\n\n\n\n\n\nFor performance reasons, .plt will randomly sample up tp max_s elements from the data (10k be default).\nYou can change the seed used for this sampling (42 by default):\n\nset_config(plt_seed=1)\na.plt(max_s=100)\n\n\n\n\n\n\n\n\n\nset_config(plt_seed=2)\na.plt(max_s=100)\n\n\n\n\n\n\n\n\nMore details in matplotlib",
    "crumbs": [
      "Misc",
      "ğŸ¤” Config"
    ]
  },
  {
    "objectID": "index.html#note-im-pretty-new-to-jax",
    "href": "index.html#note-im-pretty-new-to-jax",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Note: Iâ€™m pretty new to JAX",
    "text": "Note: Iâ€™m pretty new to JAX\nIf something does not make sense, shoot me an Issue or ping me on Discord and let me know how itâ€™s supposed to work!\nBetter support for sharded arrays and solid jit/pmap/vmap support coming soon!",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Install",
    "text": "Install\npip install lovely-jax",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "How to use",
    "text": "How to use\nHow often do you find yourself debugging JAX code? You dump an array to the cell output, and see this:\n\nnumbers\n\nArray([[[-0.35405433, -0.33692956, -0.4054286 , ..., -0.55955136,\n         -0.4739276 ,  2.2489083 ],\n        [-0.4054286 , -0.42255333, -0.49105233, ..., -0.91917115,\n         -0.8506721 ,  2.1632845 ],\n        [-0.4739276 , -0.4739276 , -0.5424266 , ..., -1.0390445 ,\n         -1.0390445 ,  2.1975338 ],\n        ...,\n        [-0.9020464 , -0.8335474 , -0.9362959 , ..., -1.4671633 ,\n         -1.2959158 ,  2.2317834 ],\n        [-0.8506721 , -0.78217316, -0.9362959 , ..., -1.6041614 ,\n         -1.5014129 ,  2.1804092 ],\n        [-0.8335474 , -0.81642264, -0.9705454 , ..., -1.6555357 ,\n         -1.5527872 ,  2.11191   ]],\n\n       [[-0.19747896, -0.19747896, -0.30252096, ..., -0.47759098,\n         -0.37254897,  2.4110641 ],\n        [-0.24999997, -0.23249297, -0.33753496, ..., -0.705182  ,\n         -0.670168  ,  2.3585434 ],\n        [-0.30252096, -0.28501397, -0.39005598, ..., -0.740196  ,\n         -0.810224  ,  2.3760502 ],\n        ...,\n        [-0.42507   , -0.23249297, -0.37254897, ..., -1.0903361 ,\n         -1.0203081 ,  2.4285715 ],\n        [-0.39005598, -0.23249297, -0.42507   , ..., -1.230392  ,\n         -1.230392  ,  2.4110641 ],\n        [-0.40756297, -0.28501397, -0.47759098, ..., -1.2829131 ,\n         -1.2829131 ,  2.3410363 ]],\n\n       [[-0.67154676, -0.9852723 , -0.88069713, ..., -0.9678431 ,\n         -0.68897593,  2.3959913 ],\n        [-0.7238344 , -1.0724182 , -0.9678431 , ..., -1.2467101 ,\n         -1.0201306 ,  2.3262744 ],\n        [-0.82840955, -1.1247058 , -1.0201306 , ..., -1.2641394 ,\n         -1.1595641 ,  2.3785625 ],\n        ...,\n        [-1.229281  , -1.4732897 , -1.3861438 , ..., -1.5081482 ,\n         -1.2641394 ,  2.5179958 ],\n        [-1.1944225 , -1.4558606 , -1.4210021 , ..., -1.6475817 ,\n         -1.4732897 ,  2.4308496 ],\n        [-1.229281  , -1.5255773 , -1.5081482 , ..., -1.68244   ,\n         -1.5255773 ,  2.3611329 ]]], dtype=float32)\n\n\nWas it really useful for you, as a human, to see all these numbers?\nWhat is the shape? The size?\nWhat are the statistics?\nAre any of the values nan or inf?\nIs it an image of a man holding a tench?\n\nimport lovely_jax as lj\n\n\nlj.monkey_patch()",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#summary",
    "href": "index.html#summary",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Summary",
    "text": "Summary\n\nnumbers\n\nArray[196, 196, 3] n=115248 (0.4Mb) xâˆˆ[-2.118, 2.640] Î¼=-0.388 Ïƒ=1.073 cpu:0\n\n\nBetter, huh?\n\nnumbers[1,:6,1] # Still shows values if there are not too many.\n\nArray[6] xâˆˆ[-0.408, -0.232] Î¼=-0.340 Ïƒ=0.075 cpu:0 [-0.250, -0.232, -0.338, -0.408, -0.408, -0.408]\n\n\n\nspicy = numbers.flatten()[:12].copy()\n\nspicy = (spicy  .at[0].mul(10000)\n                .at[1].divide(10000)\n                .at[2].set(float('inf'))\n                .at[3].set(float('-inf'))\n                .at[4].set(float('nan'))\n                .reshape((2,6)))\nspicy # Spicy stuff\n\n\nArray[2, 6] n=12 xâˆˆ[-3.541e+03, -1.975e-05] Î¼=-393.848 Ïƒ=1.113e+03 +Inf! -Inf! NaN! cpu:0\n\n\n\n\njnp.zeros((10, 10)) # A zero array - make it obvious\n\n\nArray[10, 10] n=100 all_zeros cpu:0\n\n\n\n\nspicy.v # Verbose\n\n\nArray[2, 6] n=12 xâˆˆ[-3.541e+03, -1.975e-05] Î¼=-393.848 Ïƒ=1.113e+03 +Inf! -Inf! NaN! cpu:0\nArray([[-3.5405432e+03, -1.9747897e-05,            inf,           -inf,\n                   nan, -9.8527229e-01],\n       [-4.0542859e-01, -3.0252096e-01, -8.8069713e-01, -4.3967807e-01,\n        -3.0252096e-01, -7.7612197e-01]], dtype=float32)\n\n\n\n\nspicy.p # The plain old way\n\nArray([[-3.5405432e+03, -1.9747897e-05,            inf,           -inf,\n                   nan, -9.8527229e-01],\n       [-4.0542859e-01, -3.0252096e-01, -8.8069713e-01, -4.3967807e-01,\n        -3.0252096e-01, -7.7612197e-01]], dtype=float32)",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#going-.deeper",
    "href": "index.html#going-.deeper",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Going .deeper",
    "text": "Going .deeper\n\nnumbers.deeper\n\nArray[196, 196, 3] n=115248 (0.4Mb) xâˆˆ[-2.118, 2.640] Î¼=-0.388 Ïƒ=1.073 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.912, 2.411] Î¼=-0.728 Ïƒ=0.519 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.861, 2.359] Î¼=-0.778 Ïƒ=0.450 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.758, 2.379] Î¼=-0.838 Ïƒ=0.437 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.656, 2.466] Î¼=-0.878 Ïƒ=0.415 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.717, 2.448] Î¼=-0.882 Ïƒ=0.399 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.717, 2.431] Î¼=-0.905 Ïƒ=0.408 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.563, 2.448] Î¼=-0.859 Ïƒ=0.416 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.475, 2.431] Î¼=-0.791 Ïƒ=0.463 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.526, 2.429] Î¼=-0.759 Ïƒ=0.499 cpu:0\n  ...\n\n\n\n# You can go deeper if you need to\nnumbers[:3,:5,:3].deeper(2)\n\nArray[3, 5, 3] n=45 xâˆˆ[-1.316, -0.197] Î¼=-0.593 Ïƒ=0.302 cpu:0\n  Array[5, 3] n=15 xâˆˆ[-0.985, -0.197] Î¼=-0.491 Ïƒ=0.267 cpu:0\n    Array[3] xâˆˆ[-0.672, -0.197] Î¼=-0.408 Ïƒ=0.197 cpu:0 [-0.354, -0.197, -0.672]\n    Array[3] xâˆˆ[-0.985, -0.197] Î¼=-0.507 Ïƒ=0.343 cpu:0 [-0.337, -0.197, -0.985]\n    Array[3] xâˆˆ[-0.881, -0.303] Î¼=-0.530 Ïƒ=0.252 cpu:0 [-0.405, -0.303, -0.881]\n    Array[3] xâˆˆ[-0.776, -0.303] Î¼=-0.506 Ïƒ=0.199 cpu:0 [-0.440, -0.303, -0.776]\n    Array[3] xâˆˆ[-0.916, -0.215] Î¼=-0.506 Ïƒ=0.298 cpu:0 [-0.388, -0.215, -0.916]\n  Array[5, 3] n=15 xâˆˆ[-1.212, -0.232] Î¼=-0.609 Ïƒ=0.302 cpu:0\n    Array[3] xâˆˆ[-0.724, -0.250] Î¼=-0.460 Ïƒ=0.197 cpu:0 [-0.405, -0.250, -0.724]\n    Array[3] xâˆˆ[-1.072, -0.232] Î¼=-0.576 Ïƒ=0.360 cpu:0 [-0.423, -0.232, -1.072]\n    Array[3] xâˆˆ[-0.968, -0.338] Î¼=-0.599 Ïƒ=0.268 cpu:0 [-0.491, -0.338, -0.968]\n    Array[3] xâˆˆ[-0.968, -0.408] Î¼=-0.651 Ïƒ=0.235 cpu:0 [-0.577, -0.408, -0.968]\n    Array[3] xâˆˆ[-1.212, -0.408] Î¼=-0.761 Ïƒ=0.336 cpu:0 [-0.662, -0.408, -1.212]\n  Array[5, 3] n=15 xâˆˆ[-1.316, -0.285] Î¼=-0.677 Ïƒ=0.306 cpu:0\n    Array[3] xâˆˆ[-0.828, -0.303] Î¼=-0.535 Ïƒ=0.219 cpu:0 [-0.474, -0.303, -0.828]\n    Array[3] xâˆˆ[-1.125, -0.285] Î¼=-0.628 Ïƒ=0.360 cpu:0 [-0.474, -0.285, -1.125]\n    Array[3] xâˆˆ[-1.020, -0.390] Î¼=-0.651 Ïƒ=0.268 cpu:0 [-0.542, -0.390, -1.020]\n    Array[3] xâˆˆ[-1.003, -0.478] Î¼=-0.708 Ïƒ=0.219 cpu:0 [-0.645, -0.478, -1.003]\n    Array[3] xâˆˆ[-1.316, -0.513] Î¼=-0.865 Ïƒ=0.336 cpu:0 [-0.765, -0.513, -1.316]",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#now-in-.rgb-color",
    "href": "index.html#now-in-.rgb-color",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Now in .rgb color",
    "text": "Now in .rgb color\nThe important queston - is it our man?\n\nnumbers.rgb\n\n\n\n\n\n\n\n\nMaaaaybe? Looks like someone normalized him.\n\nin_stats = ( (0.485, 0.456, 0.406),     # mean\n             (0.229, 0.224, 0.225) )    # std\n\n# numbers.rgb(in_stats, cl=True) # For channel-last input format\nnumbers.rgb(in_stats)\n\n\n\n\n\n\n\n\nItâ€™s indeed our hero, the Tenchman!",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#plt-the-statistics",
    "href": "index.html#plt-the-statistics",
    "title": "ğŸ’˜ Lovely JAX",
    "section": ".plt the statistics",
    "text": ".plt the statistics\n\n(numbers+3).plt\n\n\n\n\n\n\n\n\n\n(numbers+3).plt(center=\"mean\", max_s=1000)\n\n\n\n\n\n\n\n\n\n(numbers+3).plt(center=\"range\")",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#see-the-.chans",
    "href": "index.html#see-the-.chans",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "See the .chans",
    "text": "See the .chans\n\n# .chans will map values betwen [-1,1] to colors.\n# Make our values fit into that range to avoid clipping.\nmean = jnp.array(in_stats[0])\nstd = jnp.array(in_stats[1])\nnumbers_01 = (numbers*std + mean)\nnumbers_01\n\nArray[196, 196, 3] n=115248 (0.4Mb) xâˆˆ[0., 1.000] Î¼=0.361 Ïƒ=0.248 cpu:0\n\n\n\nnumbers_01.chans",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#grouping",
    "href": "index.html#grouping",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Grouping",
    "text": "Grouping\n\n# Make 8 images with progressively higher brightness and stack them 2x2x2.\neight_images = (jnp.stack([numbers]*8) + jnp.linspace(-2, 2, 8)[:,None,None,None])\neight_images = (eight_images\n                     *jnp.array(in_stats[1])\n                     +jnp.array(in_stats[0])\n                ).clip(0,1).reshape(2,2,2,196,196,3)\n\neight_images\n\nArray[2, 2, 2, 196, 196, 3] n=921984 (3.5Mb) xâˆˆ[0., 1.000] Î¼=0.382 Ïƒ=0.319 cpu:0\n\n\n\neight_images.rgb",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#sharding",
    "href": "index.html#sharding",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Sharding",
    "text": "Sharding\n\nassert jax.__version_info__[0] == 0\nfrom jax.sharding import NamedSharding, Mesh, PartitionSpec as P\nfrom jax.experimental import mesh_utils\n\n# Create a mesh with named axes\ndevices = mesh_utils.create_device_mesh((4, 2))\nmesh = Mesh(devices, axis_names=('y', 'x'))\n\n# Create sharding with PartitionSpec\nsharding = NamedSharding(mesh, P('y', 'x'))\n\nx = jax.random.normal(jax.random.PRNGKey(0), (8192, 8192))\ny = jax.device_put(x, sharding)\n\njax.debug.visualize_array_sharding(y)\n\nprint(y)\n\n                        \n   CPU 0       CPU 1    \n                        \n                        \n   CPU 2       CPU 3    \n                        \n                        \n   CPU 4       CPU 5    \n                        \n                        \n   CPU 6       CPU 7    \n                        \n\n\n\nArray[8192, 8192] n=67108864 (0.2Gb) xâˆˆ[-5.420, 5.220] Î¼=1.508e-05 Ïƒ=1.000 S[y,x] 4Ã—2 cpu:0-7",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#options-docs",
    "href": "index.html#options-docs",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Options | Docs",
    "text": "Options | Docs\n\nfrom lovely_jax import set_config, config\n\n\nset_config(precision=5, sci_mode=True, color=False)\njnp.array([1., 2, jnp.nan])\n\nArray[3] Î¼=1.50000e+00 Ïƒ=5.00000e-01 NaN! cpu:0 [1.00000e+00, 2.00000e+00, nan]\n\n\n\nset_config(precision=None, sci_mode=None, color=None) # None -&gt; Reset to defaults\n\n\nprint(jnp.array([1., 2]))\n# Or with config context manager.\nwith config(sci_mode=True, precision=5):\n    print(jnp.array([1., 2]))\n\nprint(jnp.array([1., 2]))\n\nArray[2] Î¼=1.500 Ïƒ=0.500 cpu:0 [1.000, 2.000]\nArray[2] Î¼=1.50000e+00 Ïƒ=5.00000e-01 cpu:0 [1.00000e+00, 2.00000e+00]\nArray[2] Î¼=1.500 Ïƒ=0.500 cpu:0 [1.000, 2.000]",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#without-.monkey_patch",
    "href": "index.html#without-.monkey_patch",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Without .monkey_patch",
    "text": "Without .monkey_patch\n\nlj.lovely(spicy)\n\n\nArray[2, 6] n=12 xâˆˆ[-3.541e+03, -1.975e-05] Î¼=-393.848 Ïƒ=1.113e+03 +Inf! -Inf! NaN! cpu:0\n\n\n\n\nlj.lovely(spicy, verbose=True)\n\n\nArray[2, 6] n=12 xâˆˆ[-3.541e+03, -1.975e-05] Î¼=-393.848 Ïƒ=1.113e+03 +Inf! -Inf! NaN! cpu:0\nArray([[-3.5405432e+03, -1.9747897e-05,            inf,           -inf,\n                   nan, -9.8527229e-01],\n       [-4.0542859e-01, -3.0252096e-01, -8.8069713e-01, -4.3967807e-01,\n        -3.0252096e-01, -7.7612197e-01]], dtype=float32)\n\n\n\n\nlj.lovely(numbers, depth=1)\n\nArray[196, 196, 3] n=115248 (0.4Mb) xâˆˆ[-2.118, 2.640] Î¼=-0.388 Ïƒ=1.073 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.912, 2.411] Î¼=-0.728 Ïƒ=0.519 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.861, 2.359] Î¼=-0.778 Ïƒ=0.450 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.758, 2.379] Î¼=-0.838 Ïƒ=0.437 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.656, 2.466] Î¼=-0.878 Ïƒ=0.415 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.717, 2.448] Î¼=-0.882 Ïƒ=0.399 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.717, 2.431] Î¼=-0.905 Ïƒ=0.408 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.563, 2.448] Î¼=-0.859 Ïƒ=0.416 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.475, 2.431] Î¼=-0.791 Ïƒ=0.463 cpu:0\n  Array[196, 3] n=588 xâˆˆ[-1.526, 2.429] Î¼=-0.759 Ïƒ=0.499 cpu:0\n  ...\n\n\n\nlj.rgb(numbers, in_stats)\n\n\n\n\n\n\n\n\n\nlj.plot(numbers, center=\"mean\")\n\n\n\n\n\n\n\n\n\nlj.chans(numbers_01)",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#matplotlib-integration-docs",
    "href": "index.html#matplotlib-integration-docs",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Matplotlib integration | Docs",
    "text": "Matplotlib integration | Docs\n\nnumbers.rgb(in_stats).fig # matplotlib figure\n\n\n\n\n\n\n\n\n\n(numbers*0.3+0.5).chans.fig # matplotlib figure\n\n\n\n\n\n\n\n\n\nnumbers.plt.fig.savefig('pretty.svg') # Save it\n\n\n!file pretty.svg; rm pretty.svg\n\npretty.svg: SVG Scalable Vector Graphics image\n\n\n\nAdd content to existing Axes\n\nfig = plt.figure(figsize=(8,3))\nfig.set_constrained_layout(True)\ngs = fig.add_gridspec(2,2)\nax1 = fig.add_subplot(gs[0, :])\nax2 = fig.add_subplot(gs[1, 0])\nax3 = fig.add_subplot(gs[1,1:])\n\nax2.set_axis_off()\nax3.set_axis_off()\n\nnumbers_01.plt(ax=ax1)\nnumbers_01.rgb(ax=ax2)\nnumbers_01.chans(ax=ax3);",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "index.html#import-hook",
    "href": "index.html#import-hook",
    "title": "ğŸ’˜ Lovely JAX",
    "section": "Import hook",
    "text": "Import hook\nLovely JAX installs an import hook. Set LOVELY_JAX=1, and it will load automatically, no need to modify the code:\n\nNote: You can now set it globally. The installed import hook will trigger only when JAX is imported.\n\nimport jax\n\nx = jax.random.normal(jax.random.PRNGKey(0), (4, 16))\nprint(x)\nLOVELY_JAX=1 python test.py\nx: Array[4, 16] n=64 xâˆˆ[-1.955, 2.180] Î¼=0.031 Ïƒ=0.960 cpu:0\nThis is especially useful in combination with Better Exceptions:\nimport jax\nimport jax.numpy as jnp\n\nx = jax.random.normal(jax.random.PRNGKey(0), (4, 16))\nprint(f\"x: {x}\")\n\nw = jax.random.normal(jax.random.PRNGKey(1), (15, 8))\ny = jnp.matmul(x, w)  # Dimension mismatch\nBETTER_EXCEPTIONS=1 LOVELY_JAX=1 python test.py\nx: Array[4, 16] n=64 xâˆˆ[-1.955, 2.180] Î¼=0.031 Ïƒ=0.960 cpu:0\nTraceback (most recent call last):\n  File \"/home/xl0/work/projects/lovely-jax/test.py\", line 9, in &lt;module&gt;\n    y = jnp.matmul(x, w)  # Dimension mismatch\n        â”‚          â”‚  â”” Array[15, 8] n=120 xâˆˆ[-2.746, 2.608] Î¼=-0.003 Ïƒ=1.072 cpu:0\n        â”‚          â”” Array[4, 16] n=64 xâˆˆ[-1.955, 2.180] Î¼=0.031 Ïƒ=0.960 cpu:0\n        â”” &lt;module 'jax.numpy' from '...'&gt;\n  File \"...jax/_src/numpy/tensor_contractions.py\", line 254, in matmul\n    out = lax.dot_general(\nTypeError: dot_general requires contracting dimensions to have the same shape, got (16,) and (15,).",
    "crumbs": [
      "ğŸ’˜ Lovely JAX"
    ]
  },
  {
    "objectID": "repr_chans.html",
    "href": "repr_chans.html",
    "title": "ğŸ“º View channels",
    "section": "",
    "text": "source\n\nchans\n\n chans (x:jax.Array, cmap:str='twilight', cm_below:str='blue',\n        cm_above:str='red', cm_ninf:str='cyan', cm_pinf:str='fuchsia',\n        cm_nan:str='yellow', view_width:int=966, gutter_px:int=3,\n        frame_px:int=1, scale:int=1, cl:Any=True,\n        ax:Optional[matplotlib.axes._axes.Axes]=None)\n\nMap tensor values to colors. RGB[A] color is added as channel-last\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nArray\n\nInput, shape=([â€¦], H, W)\n\n\ncmap\nstr\ntwilight\nUse matplotlib colormap by this name\n\n\ncm_below\nstr\nblue\nColor for values below -1\n\n\ncm_above\nstr\nred\nColor for values above 1\n\n\ncm_ninf\nstr\ncyan\nColor for -inf values\n\n\ncm_pinf\nstr\nfuchsia\nColor for +inf values\n\n\ncm_nan\nstr\nyellow\nColor for NaN values\n\n\nview_width\nint\n966\nTry to produce an image at most this wide\n\n\ngutter_px\nint\n3\nDraw write gutters when tiling the images\n\n\nframe_px\nint\n1\nDraw black frame around each image\n\n\nscale\nint\n1\n\n\n\ncl\nAny\nTrue\n\n\n\nax\nOptional\nNone\n\n\n\nReturns\nChanProxy\n\n\n\n\n\n\nin_stats = ( (0.485, 0.456, 0.406), (0.229, 0.224, 0.225) )\n\nimage = jnp.load(\"mysteryman.npy\").transpose(1,2,0)\nimage = (image * jnp.array(in_stats[1]))\nimage += jnp.array(in_stats[0])\n\nimage.rgb\n\n\n\n\n\n\n\n\n\nchans(image)\n\n\n\n\n\n\n\n\n\n# In R\nimage = image.at[0:32,32:64:,0].set(-1.1) # Below min\nimage = image.at[0:32,96:128,0].set(1.1) # Above max\n# In G\nimage = image.at[0:32,64:96,1].set(float(\"nan\"))\n# In B\nimage = image.at[0:32,0:32,2].set(float(\"-inf\"))\nimage = image.at[0:32,128:128+32,2].set(float(\"+inf\"))\n\nchans(image, cmap=\"viridis\", cm_below=\"black\", cm_above=\"white\")\n\n\n\n\n\n\n\n\n\n# 4 images, stacked 2x2\nchans(jnp.stack([image]*4).reshape(2,2,196,196,3))",
    "crumbs": [
      "Data representations",
      "ğŸ“º View channels"
    ]
  },
  {
    "objectID": "matplotlib.html",
    "href": "matplotlib.html",
    "title": "ğŸ­ Matplotlib integration",
    "section": "",
    "text": ".fig\n.rgb, .chans and .plt all have a .fig attribute that returns a matplotlib figure object.\n\na = numbers.rgb.fig # matplotlib figure\nprint(type(a))\na\n\n&lt;class 'matplotlib.figure.Figure'&gt;\n\n\n\n\n\n\n\n\n\n\nnumbers.chans.fig\n\n\n\n\n\n\n\n\n\nnumbers.plt.fig\n\n\n\n\n\n\n\n\n\nnumbers.plt(center=\"mean\").fig\n\n\n\n\n\n\n\n\n\n\nSaving the figure\nYou can save the figure by calling its savefig method:\n\nnumbers.rgb.fig.savefig(\"tench.jpg\")\n\n\n!file tench.jpg; rm tench.jpg\n\ntench.jpg: JPEG image data, JFIF standard 1.01, resolution (DPI), density 100x100, segment length 16, baseline, precision 8, 196x196, components 3\n\n\n/home/xl0/mambaforge/envs/lovely/lib/python3.13/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n\n\n\n\nUsing existing Axes\nAll functions allow an ax= argument that accepts an existing Axes object into which they will plot:\n\nfig = plt.figure(figsize=(8,3))\nfig.set_constrained_layout(True)\ngs = fig.add_gridspec(2,2)\nax1 = fig.add_subplot(gs[0, :])\nax2 = fig.add_subplot(gs[1, 0])\nax3 = fig.add_subplot(gs[1,1:])\n\nax2.set_axis_off()\nax3.set_axis_off()\n\nnumbers.plt(ax=ax1)\nnumbers.rgb(ax=ax2)\nnumbers.chans(ax=ax3);\n\n\n\n\n\n\n\n\n\n\nWithout Jupyter\nBy default, the Lovely functions will call plt.close(fig) on the figures they create.\nThis prevents displaying the figures twice when running in Jupyter.\nIf you are not using Jupyter, here are 2 configuration options you might want to set:\nfig_close=False\n#!/usr/bin/env python\nfrom lovely_jax import config, set_config\n\n...\n\nset_config(fig_close=False)\nnumbers.chans()\n\n# or, using the context manager:\nwith config(fig_close=False):\n    numbers.chans()\n\nplt.show() # Will show all open figures\nfig_show=True\nIf set, lovely will call plt.show() after each figure creation.\nYou donâ€™t need to set fig_close=False manually.\nset_config(fig_show=True)\n\nnumbers.chans() # Figure generated and shown\n\n# Note, you have to use the \"call\" syntax `( )`, as figure\n# generation is not triggerd by just accessing the attribute\n\nnumbers.chans  # No figure generated\n\nf = numbers.plt.fig # figure generated, shown, and returned.\nNote, plt.show() closes all figures.",
    "crumbs": [
      "Misc",
      "ğŸ­ Matplotlib integration"
    ]
  }
]